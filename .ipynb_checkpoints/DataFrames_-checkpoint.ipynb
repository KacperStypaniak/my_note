{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d5e7dbf-6fe1-44df-954a-1c7b677286e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## tworzenie df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740506b3-4571-4bc4-967a-f2e903fe3ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# metoda z listy słowników # wsadzamy wiersz po wierszu\n",
    "\n",
    "avocados_list = [\n",
    "    {'date': '2019-11-03', 'small_sold': 10376832, 'large_sold': 7835071},\n",
    "    {'date': '2019-11-10', 'small_sold': 10717154, 'large_sold': 8561348},\n",
    "]\n",
    "\n",
    "# Convert list into DataFrame\n",
    "avocados_2019 = pd.DataFrame(avocados_list)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#metoda ze słownika list: () # wsadzamy kolumna po kolumni\n",
    "\n",
    "# Create a dictionary of lists with new data\n",
    "avocados_dict = {\n",
    "  \"date\": [\"2019-11-17\",\"2019-12-01\"],\n",
    "  \"small_sold\": [10859987,9291631],\n",
    "  \"large_sold\": [7674135,6238096]\n",
    "}\n",
    "\n",
    "# Convert dictionary into DataFrame\n",
    "avocados_2019 = pd.DataFrame(avocados_dict)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(avocados_2019)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3b8ef-6529-49cb-a9e0-b7f233470a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wsadzając słownik ze słownikami do dataframe'u mówimy DF jak chcemy by nazywały się wiersze\n",
    "\n",
    "# Dictionary of dictionaries\n",
    "import pandas as pd\n",
    "\n",
    "europe = { 'spain': { 'capital':'madrid', 'population':46.77 },\n",
    "           'france': { 'capital':'paris', 'population':66.03 },\n",
    "           'germany': { 'capital':'berlin', 'population':80.62 },\n",
    "           'norway': { 'capital':'oslo', 'population':5.084 } }\n",
    "\n",
    "europe_pd = pd.DataFrame(europe)\n",
    "\n",
    "print(europe_pd)\n",
    "\n",
    "print(europe_pd.transpose())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1965cf-5342-4b8a-ab6b-902164af55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie DF i nadawanie indexu wierszom ze zmiennej\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Build cars DataFrame\n",
    "names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']\n",
    "dr =  [True, False, False, False, True, True, True]\n",
    "cpc = [809, 731, 588, 18, 200, 70, 45]\n",
    "cars_dict = { 'country':names, 'drives_right':dr, 'cars_per_cap':cpc }\n",
    "cars = pd.DataFrame(cars_dict)\n",
    "print(cars)\n",
    "\n",
    "# Definition of row_labels\n",
    "row_labels = ['US', 'AUS', 'JPN', 'IN', 'RU', 'MOR', 'EG']\n",
    "\n",
    "# Specify row labels of cars\n",
    "\n",
    "cars.index = row_labels\n",
    "\n",
    "# Print cars again\n",
    "\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5c4c29-6c9d-40c4-ab00-7f63ef07bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie Dataframe z listy list\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "keywords_list = [['sofas', 'sofas buy'],\n",
    " ['sofas', 'buy sofas'],\n",
    " ['sofas', 'sofas prices'],\n",
    " ['sofas', 'prices sofas'],\n",
    " ['convertible sofas', 'convertible sofas buy'],\n",
    " ['convertible sofas', 'buy convertible sofas'],\n",
    " ['convertible sofas', 'convertible sofas prices'],\n",
    " ['convertible sofas', 'prices convertible sofas'],\n",
    " ['love seats', 'love seats buy'],\n",
    " ['love seats', 'buy love seats'],\n",
    " ['love seats', 'love seats prices'],\n",
    " ['love seats', 'prices love seats'],\n",
    " ['recliners', 'recliners buy'],\n",
    " ['recliners', 'buy recliners'],\n",
    " ['recliners', 'recliners prices'],\n",
    " ['recliners', 'prices recliners'],\n",
    " ['sofa beds', 'sofa beds buy'],\n",
    " ['sofa beds', 'buy sofa beds'],\n",
    " ['sofa beds', 'sofa beds prices'],\n",
    " ['sofa beds', 'prices sofa beds']]\n",
    "\n",
    "\n",
    "print(keywords_list)\n",
    "\n",
    "\n",
    "keywords_df = pd.DataFrame.from_records(keywords_list)\n",
    "\n",
    "keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee8fb2f-7728-4a13-9793-68dc799c0075",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## usuwanie duplikatów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d2b8a-7daa-4bc2-8ff7-10e184d9e65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie duplikatów (1 i więcej kolumn)\n",
    "\n",
    "store_types = sales.drop_duplicates(subset = ['store','type'])\n",
    "print(store_types.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d19934-ddc0-484c-89cc-a6a404770299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usuwanie duplikatów po wybraniu konkretnej wartości\n",
    "\n",
    "holiday_dates = sales[sales['is_holiday'] == True].drop_duplicates(subset = ['date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ba258-151a-4c53-b8e7-106ed7be5298",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## radzenie sobie z wartościami Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27c466-8092-44b8-870e-2dc5b8a47f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#puste wartości 'na'\n",
    "\n",
    "# Import matplotlib.pyplot with alias plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check individual values for missing values - sprawdzenie dla każdej wartości czy jest ona pusta\n",
    "print(avocados_2016.isna())\n",
    "\n",
    "# Check each column for missing values - sprawdzenie dla każdej kolumny- czy zawiera ona minimum jedną pustą wartość\n",
    "print(avocados_2016.isna().any())\n",
    "\n",
    "avocados_2016.isna().sum()   # sprawdzenie dla każdej kolumny ile jest w niej pustych wartości\n",
    "\n",
    "# Bar plot of missing values by variable\n",
    "avocados_2016.isna().sum().plot(kind='bar') # przedstawienie ilości pustych wartości na wykresie kolumnowym\n",
    "\n",
    "# zamienianie pustych wartości na coś innego (np. 0)\n",
    "\n",
    "avocados_filled = avocados_2016.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3047bef-c9f0-4c2e-a4ce-883d3ca390df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## filtrowanie df (konkretnych wierszy i kolumn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab975b93-17c2-419e-bba8-cb6852a068a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectowanie kolumn jako serie albo jako DF\n",
    "\n",
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Print out country column as Pandas Series\n",
    "\n",
    "print(cars['country']) # tak selectuję jako serię\n",
    "\n",
    "# Print out country column as Pandas DataFrame\n",
    "\n",
    "print(cars[['country']]) - tak selektuję jako DF\n",
    "\n",
    "# Print out DataFrame with country and drives_right columns\n",
    "\n",
    "print(cars[['country','drives_right']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1275c1cb-b058-4ca6-abfc-0dfdc1b49224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectowanie ze slice'y wierszy\n",
    "\n",
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Print out first 3 observations\n",
    "\n",
    "print(cars.loc['US':'JPN'])\n",
    "\n",
    "\n",
    "# Print out fourth, fifth and sixth observation\n",
    "\n",
    "print(cars.iloc[3:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f913520-55ad-4761-8976-fce3456dbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectowanie pojedynczego wiersza jako DF, selectowanie różnych wierszy\n",
    "\n",
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Print out observation for Japan\n",
    "\n",
    "print(cars.loc[['JPN']])\n",
    "\n",
    "# Print out observations for Australia and Egypt\n",
    "\n",
    "print(cars.loc[['AUS','EG']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f713a7d-4a8f-4a1c-8201-b594ffcc776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wybieranie kolumny,kolumn\n",
    "\n",
    "individuals = homelessness['individuals']\n",
    "\n",
    "result = high_homelessness_srt[['state','indiv_per_10k']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc69d5b-7940-414a-9edb-5f7329050565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrowanie z kolumny\n",
    "\n",
    "ind_gt_10k = homelessness[homelessness['individuals'] > 10_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e3c3b-ccc2-4f90-8937-52f9ac41a411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrowanie z kolumny na zasadzie isin\n",
    "\n",
    "regions = ('South Atlantic','Mid-Atlantic')\n",
    "\n",
    "\n",
    "# ale można też\n",
    "\n",
    "south_mid_atlantic = homelessness[homelessness['region'].isin(['South Atlantic','Mid-Atlantic'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a39bdb-4413-44c8-b6ec-2fda1b8080c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtrowanie po indeksie - tablica\n",
    "\n",
    "dogs_ind.loc[['Bella','Stella']]\n",
    "\n",
    "# filtrowanie po indeksach hierarchicznych - tu już są krotki w tablicach\n",
    "\n",
    "dogs_ind2.loc[[('Bella','Labrador'),('Stella','Doberman')]]\n",
    "\n",
    "# sortowanie po indeksie\n",
    "\n",
    "dogs_ind2.sort_index()\n",
    "\n",
    "dogs_ind2.sort_index(level=['breed','name'], ascending=[True,False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f27c2-c91c-4b1a-9bf2-0db567780084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wybieranie wierszy i kolumn po stringach (.loc)\n",
    "\n",
    "# Subset rows from India, Hyderabad to Iraq, Baghdad\n",
    "print(temperatures_srt.loc[(\"India\",\"Hyderabad\"):('Iraq','Baghdad')])\n",
    "\n",
    "# Subset columns from date to avg_temp_c\n",
    "print(temperatures_srt.loc[:,\"date\":\"avg_temp_c\"])\n",
    "\n",
    "# Subset in both directions at once\n",
    "print(temperatures_srt.loc[(\"India\",\"Hyderabad\"):('Iraq','Baghdad'),\"date\":\"avg_temp_c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a812f-7bb3-4ad8-b4aa-7b5ac473de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wybieranie wierszy i kolumn po indeksach wierszy i indeksach kolumn (.iloc)\n",
    "\n",
    "# Get 23rd row, 2nd column (index 22, 1)\n",
    "print(temperatures.iloc[22,[1]])\n",
    "\n",
    "# Use slicing to get the first 5 rows\n",
    "print(temperatures.iloc[:5])\n",
    "\n",
    "# Use slicing to get columns 3 to 4\n",
    "print(temperatures.iloc[:,[2,3]])\n",
    "\n",
    "# Use slicing in both directions at once\n",
    "print(temperatures.iloc[:5,[2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ca8f4-768a-4f34-9787-43a9dc159694",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## filtrowanie serii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e4d79-7afb-4169-9caf-bea0d35764a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean filtering na serii\n",
    "\n",
    "# Get the worldwide mean temp by year\n",
    "mean_temp_by_year = temp_by_country_city_vs_year.mean()\n",
    "\n",
    "# Filter for the year that had the highest mean temp\n",
    "print(mean_temp_by_year[mean_temp_by_year == mean_temp_by_year.max()])\n",
    "\n",
    "# Get the mean temp by city\n",
    "mean_temp_by_city = temp_by_country_city_vs_year.mean(axis='columns')\n",
    "\n",
    "\n",
    "\n",
    "# Filter for the city that had the lowest mean temp\n",
    "print(mean_temp_by_city[mean_temp_by_city == mean_temp_by_city.min()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b03129-a988-4392-a967-437e46ca7f1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## filtrowanie z kolumny - kilka warunków"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6052ab77-0f81-401f-864d-83835b498276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrowanie z kolumny przy użyciu więcej niż jednego warunku (numpy.logical_and(_or,_not))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ind_gt_10_20k = homelessness[np.logical_and(homelessness['individuals'] > 10_000, homelessness['individuals'] < 20_000)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5621b-4b65-4dbb-9956-062db5c494e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## grupowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80619550-48a9-4333-a5a6-b40fc4ecad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby\n",
    "\n",
    "dogs.groupby(\"color\")['weight_kg'].mean()\n",
    "\n",
    "dogs.groupby('color')['weight_kg'].agg([min,max,sum])\n",
    "\n",
    "# grupowanie dla więcej niż 1 kolumny z działaniem na 1 wartości\n",
    "\n",
    "dogs.groupby(['color','breed])['weight_kg'].mean()\n",
    "\n",
    "# grupowanie dla więcej niż 1 kolumny z działaniem na więcej niż 1 wartości\n",
    "              \n",
    "dogs.groupby(['color','breed'])[['weight_kg','height_cm']].mean()\n",
    "\n",
    "\n",
    "# wykonanie jakiegoś działania w grupowaniu i później porównanie tego z całością\n",
    "sales_by_type = sales.groupby(\"type\")[\"weekly_sales\"].sum()\n",
    "sales_propn_by_type = sales_by_type / sum(sales_by_type)\n",
    "\n",
    "unemp_fuel_stats = sales.groupby('type')[['unemployment','fuel_price_usd_per_l']].agg([min,max,np.mean,np.median])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217be99e-d32d-4d8f-83a3-7d87a7401c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grupowanie a następnie wybieranie elementu b który ma najwyższą najniższą wartość wg elementu a)\n",
    "\n",
    "# In which year was Star Wars not the most popular licensed theme (in terms of number of sets released that year)?\n",
    "\n",
    "y_theme_count = sets_full[sets_full['is_licensed'] == True]\n",
    "\n",
    "y_theme_count = y_theme_count.groupby(['year','parent_theme'])['set_num'].count().reset_index(name = 'count')\n",
    "\n",
    "# tutaj - bierze id tych wierszy, w których ilość jest największa per rok\n",
    "idx = y_theme_count.groupby('year')['count'].idxmax()\n",
    "\n",
    "# filtruje zestaw z licznościami per rok, po tych idikach maxów\n",
    "y_max_count = y_theme_count.loc[idx]\n",
    "\n",
    "new_era = y_max_count[y_max_count['parent_theme'] != 'Star Wars']\n",
    "\n",
    "new_era = int(new_era['year'])\n",
    "\n",
    "new_era"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4832e550-4e93-4d55-9f73-92c759ee75b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## działania na konkretnej kolumnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59763b82-2f62-4778-9294-55bee45ca0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrowanie z kolumny i wykonanie na tych rekordach jakiegoś działania dla jakiejś konkretnej kolumny\n",
    "\n",
    "sales_A = sales[sales[\"type\"] == \"A\"][\"weekly_sales\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bc4e0-e301-4afd-962e-ddf96fb74eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# średnia, mediana\n",
    "\n",
    "print(sales['weekly_sales'].mean())\n",
    "\n",
    "print(sales['weekly_sales'].median())\n",
    "\n",
    "# max, min, sum itp na tej samej zasadzie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aefdbc-5c38-45a7-90ba-fc742b7fcdee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## własna funkcja na konkretnej kolumnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7536f5-af7a-4120-a93d-969b81fe492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# własna funkcja użyta na danych żeby coś policzyć\n",
    "\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28a480-6150-4026-afda-d430f17f2728",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## pętle po dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c03657-ca56-4558-b161-c07aea96ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pętla for w dataframe, przechodzenie przez każdy wiersz\n",
    "import pandas as pd\n",
    "\n",
    "cars_doctors_per_k = pd.DataFrame({'country':['Poland','Germany','UK','Spain','Puerto Rico','Somalia','Russia']\n",
    "                     ,'cars_per_cap':[687,628,600,627,666,5,395]\n",
    "                     ,'doctors_per_cap':[3.7,4.5,3.2,4.6,1.8,0.0,3.8]}).reset_index()\n",
    "\n",
    "print(cars_doctors_per_k)\n",
    "print('\\n')\n",
    "\n",
    "# cars_doctors_per_k.set_index('country', inplace = True)\n",
    "\n",
    "for wiersz,wartosc in cars_doctors_per_k.iterrows():\n",
    "    print(wartosc['country'])\n",
    "    print(wartosc[2:])\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for wiersz,wartosc in cars_doctors_per_k.iterrows():\n",
    "    print(wartosc['country'])\n",
    "    cars_doctors_per_k['letters_in_country_name'] = cars_doctors_per_k['country'].apply(len)\n",
    "    print(i)\n",
    "    i+=1\n",
    "\n",
    "# inny cars_doctors_per_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e828612-0254-4518-a38a-fdfcca697700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inny przykład wykorzystania pętli for w dataframie\n",
    "\n",
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Adapt for loop\n",
    "for lab, row in cars.iterrows() :\n",
    "\n",
    "    print(row['country'] + ': ' + str(row['cars_per_cap']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Code for loop that adds COUNTRY column\n",
    "\n",
    "for wiersz, wartosc in cars.iterrows():\n",
    "\n",
    "    cars.loc[wiersz,'COUNTRY'] = wartosc['country'].upper()\n",
    "\n",
    "\n",
    "# # # Print cars\n",
    "print(cars)\n",
    "\n",
    "\n",
    "\n",
    "# ALE BARDZIEJ EFEKTYWNE JEST:\n",
    "\n",
    "# Import cars data\n",
    "import pandas as pd\n",
    "cars = pd.read_csv('cars.csv', index_col = 0)\n",
    "\n",
    "# Use .apply(str.upper)\n",
    "for wiersz, wartosc in cars.iterrows() :\n",
    "    cars['COUNTRY'] = cars['country'].apply(str.upper)\n",
    "\n",
    "\n",
    "print(cars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc44c6c-6a0a-4373-84cb-0bc7a766e91e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## sortowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf150e-51f3-4eba-9406-ddcecdc67dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sortowanie\n",
    "\n",
    "homelessness_ind = homelessness.sort_values('individuals')\n",
    "\n",
    "high_homelessness_srt = high_homelessness.sort_values(['indiv_per_10k'],ascending=False)\n",
    "\n",
    "nobel_winners.sort_values(['year', 'prize'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539858c5-97ad-43d6-8351-91dd917dff06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## sumy skumulowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af4b0c-c6e4-4eac-b373-46fe814b96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodawanie nowej kolumny i suma skumulowana, max skumulowany\n",
    "\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd20ef-7c96-4038-b07b-8773b4c63e63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## udział procentowy w całości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae679ef4-280f-4569-98fd-b181e51ee185",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counting + udział %\n",
    "\n",
    "unique_dogs['breed'].value_counts(opt. sort=True, opt. normalize = True)\n",
    "\n",
    "normalize - zrobienie udziału % danej wartości w całości"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a218f9-da1a-46cd-a2d2-f53f79fa093e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## transpozycja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f76b5-cc64-4850-8abb-d071e6fa7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transponowanie tabeli\n",
    "\n",
    "# Change the DataFrame so rows become columns and vice versa\n",
    "fifa_transpose = fifa_players.set_index('name')[['height', 'weight']].transpose()\n",
    "\n",
    "# Print fifa_transpose\n",
    "print(fifa_transpose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f106d-0f53-40e5-b62b-e85a45c9b6a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## pivotowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed40e6e6-ba7c-40b5-a855-59fa44b16e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot tabeli\n",
    "\n",
    "dogs.groupby('color')['weight_kg'].mean()\n",
    "=\n",
    "dogs.pivot_table(values='weight_kg',index='color')  # z defaultu pivotuje używając średniej\n",
    "\n",
    "#można użyć innej funkcji w pivocie używając aggfunc (lub kilku funkcji)\n",
    "\n",
    "import numpy as np\n",
    "dogs.pivot_table(values='weight_kg',index='color',aggfunc=np.median)\n",
    "\n",
    "dogs.pivot_table(values='weight_kg',index='color',aggfunc=[np.median,np.mean])\n",
    "\n",
    "#można przekazać drugą kolumnę (pierwsza jest w index) do columns - ale w przypadku nulli będzie NaN \n",
    "\n",
    "dogs.pivot_table(values='weight_kg',index='color',columns='breed')\n",
    "\n",
    "# Inny przykład:\n",
    "\n",
    "# Add a year column to temperatures\n",
    "temperatures['year'] = temperatures['date'].dt.year\n",
    "temperatures\n",
    "\n",
    "# Pivot avg_temp_c by country and city vs year\n",
    "temp_by_country_city_vs_year = temperatures.pivot_table(\"avg_temp_c\",index=['country','city'],columns='year')\n",
    "\n",
    "# See the result\n",
    "print(temp_by_country_city_vs_year)\n",
    "\n",
    "# żeby zastąpić NaN poprzez np. 0\n",
    "\n",
    "dogs.pivot_table(values='weight_kg',index='color',columns='breed',fill_value=0)\n",
    "\n",
    "#dodatkowo, można dodać średnie (lub sumy itp.) dla wierszy i kolumn używamy margins = True (nie uwzględni 0 przy tej średniej)\n",
    "\n",
    "dogs.pivot_table(values='weight_kg',index='color',columns='breed',fill_value=0, margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d831e-1b43-45d2-a36e-820b651b7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivotowanie tabeli w oparciu o jakąś funkcję na danych\n",
    "\n",
    "\n",
    "# Use pivot table to get all scores by name and movement\n",
    "fifa_pivot_table = fifa_players.pivot_table(index='name', \n",
    "                                     columns='movement', \n",
    "                                     aggfunc= 'mean')\n",
    "\n",
    "# Use pivot table to show the count of players by club and nationality and the total count\n",
    "players_country = fifa_players.pivot_table(index='nationality', \n",
    "                                    columns='club', \n",
    "                                    values= 'id', \n",
    "                                    aggfunc='count', \n",
    "                                    margins=True)  #doda całkowitą sumę\n",
    "\n",
    "# Print players_country\n",
    "print(players_country)\n",
    "\n",
    "\n",
    "# Define a pivot table to get the characteristic by nationality and club\n",
    "fifa_mean = fifa_players.pivot_table(index=['nationality', 'club'], \n",
    "                                     aggfunc = 'mean')  #średnia ze wszystkich kolumn\n",
    "\n",
    "# Print fifa_mean\n",
    "print(fifa_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c4911-8877-4553-8fa6-ef15274c0738",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## melting (z szerokiej tabeli na długą) i wide to long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0d6e7-0e37-4c11-af18-1b7c5e7fa2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# melting tabeli - zmiana z tabeli szerokiej na długą (horyzontalnie do wertykalnie)\n",
    "\n",
    "# Melt books_gothic using the title column as identifier \n",
    "gothic_melted = books_gothic.melt(id_vars='title')\n",
    "\n",
    "# Print gothic_melted\n",
    "print(gothic_melted)\n",
    "\n",
    "\n",
    "# Melt publisher column using title and authors as identifiers\n",
    "publisher_melted = books_gothic.melt(id_vars=['title', 'authors'], \n",
    "                                     value_vars='publisher')\n",
    "\n",
    "# Print publisher_melted\n",
    "print(publisher_melted)\n",
    "\n",
    "\n",
    "\n",
    "# Melt rating and rating_count columns using the title as identifier\n",
    "rating_melted = books_gothic.melt(id_vars='title', \n",
    "                                  value_vars=['rating', 'rating_count'])\n",
    "\n",
    "# Print rating_melted\n",
    "print(rating_melted)\n",
    "\n",
    "\n",
    "# Melt rating and rating_count columns using title and authors as identifier\n",
    "books_melted = books_gothic.melt(id_vars=['title','authors'], \n",
    "                                 value_vars= ['rating','rating_count'])\n",
    "\n",
    "# Print books_melted\n",
    "print(books_melted)\n",
    "\n",
    "\n",
    "\n",
    "# Melt the rating and rating_count using title, authors and publisher as identifiers\n",
    "books_ratings = books_gothic.melt(id_vars = ['title','authors','publisher'], \n",
    "                                  value_vars = ['rating','rating_count'])\n",
    "\n",
    "# Print books_ratings\n",
    "print(books_ratings)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assign the name feature to the new variable column\n",
    "# Assign the name number to the new column containing the values\n",
    "books_ratings = books_gothic.melt(id_vars=['title', 'authors', 'publisher'], \n",
    "                                  value_vars=['rating', 'rating_count'], \n",
    "                                  var_name='feature', \n",
    "                                  value_name= 'number')\n",
    "\n",
    "# Print books_ratings\n",
    "print(books_ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65036e9f-15c9-4f30-bd46-7abf0f03cc99",
   "metadata": {},
   "source": [
    "### wide to long\n",
    "\n",
    "melting na ogół wystarczy, ale jeżeli kolumny będą się wyróżniać sufiksami (np. 'rok_2019','rok_2020') to można zrobić jedną kolumnę rok a w inną kolumnę wrzucić (już pionowo) to 2019 i 2020\n",
    "\n",
    "\n",
    "![image.png](attachment:79d8dbac-c263-443e-81a4-09852e4420b1.png)\n",
    "\n",
    "![image.png](attachment:71ce9924-ee15-4fda-9eda-9a91392e169a.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d5ff41-2c88-4620-9323-b88658d3a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reshape wide to long using title as index and version as new name, and extracting isbn prefix \n",
    "\n",
    "\n",
    "\n",
    "#                title              authors         isbn13      isbn10  prefix13  prefix10\n",
    "# 0   The Great Gatsby  F. Scott Fitzgerald  9780060098919  1572702567       978         1\n",
    "# 1  The Short Stories     Ernest Hemingway  9780684837864   684837862       978         0\n",
    "# 2  To the Lighthouse       Virginia Woolf  9780156030472   156030470       978         0\n",
    "\n",
    "\n",
    "# golden_age\n",
    "\n",
    "# # Reshape wide to long using title as index and version as new name, and extracting isbn prefix \n",
    "# isbn_long = pd.wide_to_long(golden_age, \n",
    "#                     stubnames= ['isbn','prefix'],\n",
    "#                     i='title', \n",
    "#                     j='version')\n",
    "\n",
    "# # Print isbn_long\n",
    "# print(isbn_long)\n",
    "\n",
    "#                                        authors           isbn  prefix\n",
    "# title             version                                            \n",
    "# The Great Gatsby  13       F. Scott Fitzgerald  9780060098919     978\n",
    "# The Short Stories 13          Ernest Hemingway  9780684837864     978\n",
    "# To the Lighthouse 13            Virginia Woolf  9780156030472     978\n",
    "# The Great Gatsby  10       F. Scott Fitzgerald     1572702567       1\n",
    "# The Short Stories 10          Ernest Hemingway      684837862       0\n",
    "# To the Lighthouse 10            Virginia Woolf      156030470       0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Reshape wide to long using title and authors as index and version as new name, and prefix and isbn as wide column prefixes\n",
    "# all_long = pd.wide_to_long(golden_age, \n",
    "#                    stubnames = ['prefix','isbn'], # kolumny jakie mają zostać rozbite na swoje poszczególne wersje - budowa prefix123 - spodziewa się numeru\n",
    "#                    i = ['title','authors'], # kolumny które mają być indeksami\n",
    "#                    j = 'version') # jak się ma nazywać kolumna która zostanie utworzona by rozróżniać między są stubnames\n",
    "\n",
    "# # Print all_long\n",
    "# print(all_long)\n",
    "\n",
    "#                                                prefix           isbn\n",
    "# title             authors             version                       \n",
    "# The Great Gatsby  F. Scott Fitzgerald 13          978  9780060098919\n",
    "#                                       10            1     1572702567\n",
    "# The Short Stories Ernest Hemingway    13          978  9780684837864\n",
    "#                                       10            0      684837862\n",
    "# To the Lighthouse Virginia Woolf      13          978  9780156030472\n",
    "#                                       10            0      156030470\n",
    "\n",
    "\n",
    "\n",
    "# zrób dwa dataframe'y, połącz je ze sobą\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "books_brown = pd.DataFrame([{'title':'The Da Vinci Code'\n",
    "                             ,'authors':'Dan Brown'\n",
    "                             ,'language_code':'0'\n",
    "                             ,'language_name':'english'\n",
    "                             ,'publisher_code':12\n",
    "                             ,'publisher_name':'Random House'}]\n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "next_rows = pd.DataFrame({\n",
    "                        'title':['Angels & Demons','La fortaleza digital']\n",
    "                         ,'authors':['Dan Brown','Dan Brown']\n",
    "                         ,'language_code':[0,84]\n",
    "                         ,'language_name':['English','Spanish']\n",
    "                         ,'publisher_code':[34,43]\n",
    "                         ,'publisher_name':['Pocket Books','Umbriel']\n",
    "                        })\n",
    "\n",
    "\n",
    "books_brown = pd.concat([books_brown,next_rows]).reset_index()\n",
    "\n",
    "books_brown\n",
    "\n",
    "# zmień strukturę z szerokiej na długą, zachowując autora i tytuł jako indeks, rozbij język i wydawcę po ich sufiksach, nową kolumnę nazwij code\n",
    "# określ jaki jest separator w nazwie kolumny i podaj informację że sufiks będzie stringiem a nie liczbą\n",
    "the_code_long = pd.wide_to_long(books_brown, \n",
    "                                stubnames=['language', 'publisher'], \n",
    "                                i=['authors', 'title'], \n",
    "                                j='code', \n",
    "                                sep='_', \n",
    "                                suffix= '\\w+')\n",
    "\n",
    "# Print the_code_long\n",
    "the_code_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2811c7-2913-4f20-a339-f8dd2231e454",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## robienie z jednej z kolumn indeksu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cffd39c-ebdb-4c89-9760-40fcb2c55fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# robienie z jednej z kolumn indeksu dla tabelki\n",
    "\n",
    "dogs_ind = dogs.set_index('name') # co ważne - tak z automatu nie zajdzie tutaj żadna agregacja, wartości w indeksie mogą się duplikować\n",
    "\n",
    "#resetowanie indeksu\n",
    "dogs_ind.reset_index()\n",
    "\n",
    "# usuwanie kolumny indeksu w ogole (zniknie ta kolumna z danych)\n",
    "dogs_ind.reset_index(drop=True)\n",
    "\n",
    "\n",
    "#indeksem może być więcej niż jedna kolumna (indeksy hierarchiczne)\n",
    "\n",
    "dogs_ind2 = dogs.set_index(['name','breed'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc63e6-0b51-4247-bdc2-1dd6646bc980",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## usuwanie wierszy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f85d69-dbbc-486a-a928-6369a6626672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usuwanie wierszy\n",
    "# axis = 0 - wiersze, = 1 - kolumny\n",
    "# Drop the fifth row to delete all repeated rows\n",
    "fifa_no_rep = fifa_players.drop(4, axis=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
